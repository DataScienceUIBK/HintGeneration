{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "AILC - Lectures 2021: Training BERT-based models in few lines of code",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIqpm34x2rms",
    "outputId": "e1848ba4-193a-4da5-d0d3-f8324177be54",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:32:55.879588Z",
     "end_time": "2023-07-29T23:33:04.482446Z"
    }
   },
   "source": [
    "import torch\n",
    "import io\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##Set random values\n",
    "seed_val = 213\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeZgRup520II",
    "outputId": "4f6dbda5-57ad-4965-aceb-1304a36508e0",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:04.485445Z",
     "end_time": "2023-07-29T23:33:04.497887Z"
    }
   },
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W7cP8q7K3BId",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:04.501904Z",
     "end_time": "2023-07-29T23:33:04.542895Z"
    }
   },
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def load_qc_examples(input_file, use_fine_grained_classes=False):\n",
    "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "    examples = []\n",
    "    labels = []\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        contents = f.read()\n",
    "        file_as_list = contents.splitlines()\n",
    "        for line in file_as_list:\n",
    "            split = line.split(\" \")\n",
    "            question = ' '.join(split[1:])\n",
    "            if not use_fine_grained_classes:\n",
    "                label = split[0].split(\":\")[0]\n",
    "            else:\n",
    "                label = split[0]\n",
    "            labels.append(label)\n",
    "            examples.append((question, label))\n",
    "        f.close()\n",
    "\n",
    "    return examples, set(labels)\n",
    "\n",
    "\n",
    "def load_sentipolc_examples(input_file, skip_first_row=False):\n",
    "    \"\"\"Creates examples for the training and dev sets for the sentipolc dataset.\"\"\"\n",
    "    examples = []\n",
    "    labels = []\n",
    "\n",
    "    with open(input_file, \"r\") as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        if skip_first_row:\n",
    "            next(reader, None)  # skip the headers\n",
    "        for row in reader:\n",
    "            text = row[8]\n",
    "            label = row[1]\n",
    "            labels.append(label)\n",
    "            examples.append((text, label))\n",
    "\n",
    "    return examples, set(labels)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tG5WxZviQg6L",
    "outputId": "a28b48df-ab3a-4d6e-9191-7e32008c70aa",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:04.512896Z",
     "end_time": "2023-07-29T23:33:07.991775Z"
    }
   },
   "source": [
    "task = \"qc\"  #\"subj\"\n",
    "\n",
    "assert task == \"qc\" or task == \"subj\"\n",
    "\n",
    "if task == \"qc\":\n",
    "    #--------------------------------\n",
    "    #  Retrieve the TREC QC Dataset\n",
    "    #--------------------------------\n",
    "    os.system('wget -nc https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label')\n",
    "    os.system('wget -nc https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label')\n",
    "\n",
    "    train_filename = \"train_5500.label\"\n",
    "    test_filename = \"TREC_10.label\"\n",
    "\n",
    "    # this boolean value allows adopting the fined-grained setting\n",
    "    use_fine_grained_classes = True\n",
    "    train_examples, train_labels = load_qc_examples(train_filename, use_fine_grained_classes)\n",
    "    test_examples, test_labels = load_qc_examples(test_filename, use_fine_grained_classes)\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the SentiPolc\n",
    "#--------------------------------\n",
    "else:\n",
    "    ! wget -nc http: // www.di.unito.it/ ~tutreeb/sentipolc-evalita16/training_set_sentipolc16.csv.zip')\n",
    "    ! wget -nc http: // www.di.unito.it/ ~tutreeb/sentipolc-evalita16/test_set_sentipolc16_gold2000.csv.zip\n",
    "    ! unzip -o training_set_sentipolc16.csv.zip\n",
    "    ! unzip -o test_set_sentipolc16_gold2000.csv.zip\n",
    "\n",
    "    train_filename = \"training_set_sentipolc16.csv\"\n",
    "    test_filename = \"test_set_sentipolc16_gold2000.csv\"\n",
    "\n",
    "    train_examples, train_labels = load_sentipolc_examples(train_filename, skip_first_row=True)\n",
    "    test_examples, test_labels = load_sentipolc_examples(test_filename, skip_first_row=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gQhg7e24W8U",
    "outputId": "2e26cc1c-d572-4a17-c5f9-995dba083e50",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:07.993279Z",
     "end_time": "2023-07-29T23:33:08.007147Z"
    }
   },
   "source": [
    "print(\"Some training examples:\\n\")\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print(train_examples[i])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXCwFyF2qhw7",
    "outputId": "432cf986-e829-4f1b-f486-45f17ecd1a4b",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:08.008148Z",
     "end_time": "2023-07-29T23:33:08.051751Z"
    }
   },
   "source": [
    "# This is a multi-class classification task. \n",
    "label_list = list(train_labels.union(test_labels))\n",
    "label_list.sort()\n",
    "# Let us print the labels used in the dataset\n",
    "print(\"Target Labels:\\t\" + str(label_list))\n",
    "print(\"Number of Labels:\\t\" + str(len(label_list)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G9SpJ_KE42h4",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:08.023732Z",
     "end_time": "2023-07-29T23:33:08.051751Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "#  English models\n",
    "# --------------------------------------------\n",
    "#model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"bert-large-cased\"\n",
    "#model_name = \"bert-large-uncased\"\n",
    "#model_name = \"bert-large-uncased-whole-word-masking\"\n",
    "\n",
    "#model_name = \"roberta-base\"\n",
    "model_name = \"roberta-large\"\n",
    "\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"albert-large-v2\"\n",
    "#model_name = \"albert-xlarge-v2\"\n",
    "\n",
    "#model_name = \"google/electra-base-discriminator\"\n",
    "\n",
    "#model_name = \"distilbert-base-cased\"\n",
    "#model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Multilingual models\n",
    "# --------------------------------------------\n",
    "#model_name = \"bert-base-multilingual-cased\" #the uncased should not be used\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "\n",
    "# --------------------------------------------\n",
    "#  Italian models (my language) \n",
    "# --------------------------------------------\n",
    "#model_name = \"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\"\n",
    "#model_name = \"Musixmatch/umberto-commoncrawl-cased-v1\"\n",
    "\n",
    "# Notice that a lot of models pre-trained for specific languages are available\n",
    "# at https://huggingface.co/models"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "18kY64-n3I6y",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:08.040733Z",
     "end_time": "2023-07-29T23:33:08.061731Z"
    }
   },
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels=2, dropout_rate=0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        # Load the BERT-based encoder\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        # The AutoConfig allows to access the encoder configuration.\n",
    "        # The configuration is needed to derive the size of the embedding, which\n",
    "        # is produced by BERT (and similar models) to encode the input elements.\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        self.cls_size = int(config.hidden_size)\n",
    "        # Dropout is applied before the final classifier\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        # Final linear classifier\n",
    "        self.fully_connected_layer = nn.Linear(self.cls_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # encode all outputs\n",
    "        model_outputs = self.encoder(input_ids, attention_mask)\n",
    "        # just select the vector associated to the [CLS] symbol used as\n",
    "        # first token for ALL sentences\n",
    "        encoded_cls = model_outputs.last_hidden_state[:, 0]\n",
    "        # apply dropout\n",
    "        encoded_cls_dp = self.input_dropout(encoded_cls)\n",
    "        # apply the linear classifier\n",
    "        logits = self.fully_connected_layer(encoded_cls_dp)\n",
    "        # return the logits\n",
    "        return logits, encoded_cls"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "tuE0-kd7nsWK",
    "outputId": "0ca9bc86-3399-4b3c-9cd5-cfad29175e1f",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:08.055733Z",
     "end_time": "2023-07-29T23:33:09.149843Z"
    }
   },
   "source": [
    "# Define a Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "#Print the length distribution\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist([len(tokenizer.encode_plus(text)[\"input_ids\"]) for text, label in train_examples], bins=20)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jw0HC_hU3FUy",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:09.149843Z",
     "end_time": "2023-07-29T23:33:09.186930Z"
    }
   },
   "source": [
    "# --------------------------------\n",
    "# Encoder (i.e., BERT) parameters\n",
    "# --------------------------------\n",
    "\n",
    "# the maximum length to be considered in input\n",
    "max_seq_length = 64\n",
    "# dropout applied to the embedding produced by BERT before the classifiation\n",
    "out_dropout_rate = 0.1\n",
    "\n",
    "# --------------------------------\n",
    "# Training parameters\n",
    "# --------------------------------\n",
    "\n",
    "# Dev percentage split, i.e., the percentage of training material to be use for\n",
    "# evaluating the model during training\n",
    "dev_perc = 0.1\n",
    "\n",
    "# the batch size\n",
    "batch_size = 64\n",
    "\n",
    "# the learning rate used during the training process\n",
    "learning_rate = 2e-5\n",
    "# if you use large models (such as Bert-large) it is a good idea to use \n",
    "# smaller values, such as 5e-6\n",
    "\n",
    "# name of the fine_tuned_model\n",
    "output_model_name = \"best_qc_model.pickle\"\n",
    "\n",
    "# number of training epochs\n",
    "num_train_epochs = 6\n",
    "\n",
    "# ADVANCED: Schedulers allow to define dynamic learning rates.\n",
    "# You can find all available schedulers here\n",
    "# https://huggingface.co/transformers/main_classes/optimizer_schedules.html\n",
    "apply_scheduler = False\n",
    "# Here a `Constant schedule with warmup`can be activated. More details here\n",
    "# https://huggingface.co/transformers/main_classes/optimizer_schedules.html#transformers.get_constant_schedule_with_warmup\n",
    "warmup_proportion = 0.1\n",
    "\n",
    "# --------------------------------\n",
    "# Log parameters\n",
    "# --------------------------------\n",
    "\n",
    "# Print a log each n steps\n",
    "print_each_n_step = 10\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fmKL5AD7I4Zg",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:09.172925Z",
     "end_time": "2023-07-29T23:33:09.186930Z"
    }
   },
   "source": [
    "def generate_data_loader(examples, label_map, tokenizer, do_shuffle=False):\n",
    "    '''\n",
    "    Generate a Dataloader given the input examples\n",
    "\n",
    "    examples: a list of pairs (input_text, label)\n",
    "    label_mal: a dictionary used to assign an ID to each label\n",
    "    tokenize: the tokenizer used to convert input sentences into word pieces\n",
    "    do_shuffle: a boolean parameter to shuffle input examples (usefull in training)\n",
    "    '''\n",
    "    #-----------------------------------------------\n",
    "    # Generate input examples to the Transformer\n",
    "    #-----------------------------------------------\n",
    "    input_ids = []\n",
    "    input_mask_array = []\n",
    "    label_id_array = []\n",
    "\n",
    "    # Tokenization\n",
    "    for (text, label) in examples:\n",
    "        # tokenizer.encode_plus is a crucial method which:\n",
    "        # 1. tokenizes examples\n",
    "        # 2. trims sequences to a max_seq_length\n",
    "        # 3. applies a pad to shorter sequences\n",
    "        # 4. assigns the [CLS] special wor-piece such as the other ones (e.g., [SEP])\n",
    "        encoded_sent = tokenizer.encode_plus(text, add_special_tokens=True, max_length=max_seq_length,\n",
    "                                             padding='max_length', truncation=True)\n",
    "        # convert input word pieces to IDs of the corresponding input embeddings\n",
    "        input_ids.append(encoded_sent['input_ids'])\n",
    "        # store the attention mask to avoid computations over \"padded\" elements\n",
    "        input_mask_array.append(encoded_sent['attention_mask'])\n",
    "\n",
    "        # converts labels to IDs\n",
    "        id = -1\n",
    "        if label in label_map:\n",
    "            id = label_map[label]\n",
    "        label_id_array.append(id)\n",
    "\n",
    "    # Convert to Tensor which are used in PyTorch\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    input_mask_array = torch.tensor(input_mask_array)\n",
    "    label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "\n",
    "    # Building the TensorDataset\n",
    "    dataset = TensorDataset(input_ids, input_mask_array, label_id_array)\n",
    "\n",
    "    if do_shuffle:\n",
    "        # this will shuffle examples each time a new batch is required\n",
    "        sampler = RandomSampler\n",
    "    else:\n",
    "        sampler = SequentialSampler\n",
    "\n",
    "    # Building the DataLoader\n",
    "    return DataLoader(\n",
    "        dataset,  # The training samples.\n",
    "        sampler=sampler(dataset),  # the adopted sampler\n",
    "        batch_size=batch_size)  # Trains with this batch size.\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4c-nsMXlKX-D",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dc7187a0-5ea5-4d8e-9042-5e93cd598453",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:09.182929Z",
     "end_time": "2023-07-29T23:33:09.618458Z"
    }
   },
   "source": [
    "# Initialize a map to associate labels to the dimension of the embedding \n",
    "# produced by the classifier\n",
    "label_to_id_map = {}\n",
    "id_to_label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "    label_to_id_map[label] = i\n",
    "    id_to_label_map[i] = label\n",
    "\n",
    "with open('label_to_id.pickle', mode='wb') as f:\n",
    "    pickle.dump(label_to_id_map, f)\n",
    "\n",
    "with open('id_to_label.pickle', mode='wb') as f:\n",
    "    pickle.dump(id_to_label_map, f)\n",
    "\n",
    "# Shuffle and split the training material in train/dev\n",
    "random.shuffle(train_examples)\n",
    "train_subset_examples = train_examples[int(len(train_examples) * 0): int(len(train_examples) * (1 - dev_perc))]\n",
    "dev_subset_examples = train_examples[int(len(train_examples) * (1 - dev_perc)): int(len(train_examples))]\n",
    "\n",
    "# Build the Train Dataloader\n",
    "train_dataloader = generate_data_loader(train_subset_examples, label_to_id_map, tokenizer, do_shuffle=True)\n",
    "# Build the Development Dataloader\n",
    "dev_dataloader = generate_data_loader(dev_subset_examples, label_to_id_map, tokenizer, do_shuffle=True)\n",
    "# Build the Test DataLoader\n",
    "test_dataloader = generate_data_loader(test_examples, label_to_id_map, tokenizer, do_shuffle=False)\n",
    "\n",
    "print(\"Number of training examples:\\t\" + str(len(train_subset_examples)))\n",
    "print(\"Number of development examples:\\t\" + str(len(dev_subset_examples)))\n",
    "print(\"Number of test examples:\\t\" + str(len(test_examples)))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "43aKjn18lLxQ",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:09.625457Z",
     "end_time": "2023-07-29T23:33:09.633889Z"
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "\n",
    "\n",
    "def evaluate(dataloader, classifier, print_classification_output=False, print_result_summary=False):\n",
    "    '''\n",
    "    Evaluation method which will be applied to development and test datasets.\n",
    "    It returns the pair (average loss, accuracy)\n",
    "\n",
    "    dataloader: a dataloader containing examples to be classified\n",
    "    classifier: the BERT-based classifier\n",
    "    print_classification_output: to log the classification outcomes\n",
    "    '''\n",
    "    total_loss = 0\n",
    "    gold_classes = []\n",
    "    system_classes = []\n",
    "\n",
    "    if print_classification_output:\n",
    "        print(\"\\n------------------------\")\n",
    "        print(\"  Classification outcomes\")\n",
    "        print(\"is_correct\\tgold_label\\tsystem_label\\ttext\")\n",
    "        print(\"------------------------\")\n",
    "\n",
    "    # For each batch of examples from the input dataloader\n",
    "    for batch in dataloader:\n",
    "        # Unpack this training batch from our dataloader. Notice this is populated\n",
    "        # in the method `generate_data_loader`\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "            # Each batch is classifed\n",
    "            logits, _ = classifier(b_input_ids, b_input_mask)\n",
    "            # Evaluate the loss.\n",
    "            total_loss += nll_loss(logits, b_labels)\n",
    "\n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        system_classes += preds.detach().cpu()\n",
    "        gold_classes += b_labels.detach().cpu()\n",
    "\n",
    "        # Print the output of the classification for each input element\n",
    "        if print_classification_output:\n",
    "            for ex_id in range(len(b_input_mask)):\n",
    "                input_strings = tokenizer.decode(b_input_ids[ex_id], skip_special_tokens=True)\n",
    "                # convert class id to the real label\n",
    "                predicted_label = id_to_label_map[preds[ex_id].item()]\n",
    "                gold_standard_label = \"UNKNOWN\"\n",
    "                # convert the gold standard class ID into a real label\n",
    "                if b_labels[ex_id].item() in id_to_label_map:\n",
    "                    gold_standard_label = id_to_label_map[b_labels[ex_id].item()]\n",
    "                # put the prefix \"[OK]\" if the classification is correct\n",
    "                output = '[OK]' if predicted_label == gold_standard_label else '[NO]'\n",
    "                # print the output\n",
    "                print(output + \"\\t\" + gold_standard_label + \"\\t\" + predicted_label + \"\\t\" + input_strings)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_loss = avg_loss.item()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    system_classes = torch.stack(system_classes).numpy()\n",
    "    gold_classes = torch.stack(gold_classes).numpy()\n",
    "    accuracy = np.sum(system_classes == gold_classes) / len(system_classes)\n",
    "\n",
    "    if print_result_summary:\n",
    "        print(\"\\n------------------------\")\n",
    "        print(\"  Summary\")\n",
    "        print(\"------------------------\")\n",
    "        #remove unused classes in the test material\n",
    "        filtered_label_list = []\n",
    "        for i in range(len(label_list)):\n",
    "            if i in gold_classes:\n",
    "                filtered_label_list.append(id_to_label_map[i])\n",
    "        print(classification_report(gold_classes, system_classes, digits=3, target_names=filtered_label_list))\n",
    "\n",
    "        print(\"\\n------------------------\")\n",
    "        print(\"  Confusion Matrix\")\n",
    "        print(\"------------------------\")\n",
    "        conf_mat = confusion_matrix(gold_classes, system_classes)\n",
    "        for row_id in range(len(conf_mat)):\n",
    "            print(filtered_label_list[row_id] + \"\\t\" + str(conf_mat[row_id]))\n",
    "\n",
    "    return avg_loss, accuracy"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vdImjZjujKxh",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:09.636890Z",
     "end_time": "2023-07-29T23:33:12.203875Z"
    }
   },
   "source": [
    "classifier = Classifier(model_name, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    classifier.cuda()\n",
    "\n",
    "# Define the Optimizer. Here the ADAM optimizer (a sort of standard de-facto) is\n",
    "# used. AdamW is a variant which also adopts Weigth Decay.\n",
    "optimizer = torch.optim.AdamW(classifier.parameters(), lr=learning_rate)\n",
    "# More details about the Optimizers can be found here:\n",
    "# https://huggingface.co/transformers/main_classes/optimizer_schedules.html\n",
    "\n",
    "# Define the scheduler\n",
    "if apply_scheduler:\n",
    "    # Estimate the numbers of step corresponding to the warmup.\n",
    "    num_train_examples = len(train_examples)\n",
    "    num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "    # Initialize the scheduler\n",
    "    scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oG4bBwD4XqFh",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:12.200846Z",
     "end_time": "2023-07-29T23:33:12.219846Z"
    }
   },
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NhqylHGK3Va4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "76e51daf-5507-44da-917a-d6baa5e03274",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:33:12.215847Z",
     "end_time": "2023-07-29T23:42:34.157366Z"
    }
   },
   "source": [
    "training_stats = []\n",
    "\n",
    "# Define the LOSS function. A CrossEntropyLoss is used for multi-class \n",
    "# classification tasks. \n",
    "nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "# All loss functions are available at:\n",
    "# - https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# NOTICE: the measure to be maximized should depends on the task. \n",
    "# Here accuracy is used.\n",
    "best_dev_accuracy = -1\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    train_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    classifier.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        train_logits, _ = classifier(b_input_ids, b_input_mask)\n",
    "        # calculate the loss        \n",
    "        loss = nll_loss(train_logits, b_labels)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler, if specified\n",
    "        if apply_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #     Evaluate on the Development set\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    classifier.eval()\n",
    "\n",
    "    # Apply the evaluate_method defined above to estimate \n",
    "    avg_dev_loss, dev_accuracy = evaluate(test_dataloader, classifier)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Accuracy: {0:.3f}\".format(dev_accuracy))\n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_dev_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_dev_loss,\n",
    "            'Valid. Accur.': dev_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Save the model if the performance on the development set increases\n",
    "    if dev_accuracy > best_dev_accuracy:\n",
    "        best_dev_accuracy = dev_accuracy\n",
    "        torch.save(classifier, output_model_name)\n",
    "        print(\"\\n  Saving the model during epoch \" + str(epoch_i))\n",
    "        print(\"  Actual Best Validation Accuracy: {0:.3f}\".format(best_dev_accuracy))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dDm9NProRB4c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "outputId": "16e60f2f-b3b9-44d8-ef74-49926b105076",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:42:34.162370Z",
     "end_time": "2023-07-29T23:42:34.537017Z"
    }
   },
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for stat in training_stats:\n",
    "    train_losses.append(stat[\"Training Loss\"])\n",
    "    val_losses.append(stat[\"Valid. Loss\"])\n",
    "    val_acc.append(stat[\"Valid. Accur.\"])\n",
    "    print(stat)\n",
    "\n",
    "plt.plot(range(1, num_train_epochs + 1), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(1, num_train_epochs + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, num_train_epochs + 1), val_acc, label=\"Val Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Val. Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lEiQBIJ3neHn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9ba192d4-1038-4860-805a-366315d4a6aa",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:42:34.538527Z",
     "end_time": "2023-07-29T23:42:39.571575Z"
    }
   },
   "source": [
    "# Load the best model\n",
    "nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "best_model = torch.load(output_model_name)\n",
    "\n",
    "# Evaluate it\n",
    "avg_test_loss, test_accuracy = evaluate(test_dataloader, best_model, print_classification_output=True,\n",
    "                                        print_result_summary=False)\n",
    "\n",
    "print(\"\\n\\n  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kVz0_R0vhY6y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f414faec-d6e9-4ec8-c7a6-deba9b2d43d4",
    "ExecuteTime": {
     "start_time": "2023-07-29T23:42:39.570575Z",
     "end_time": "2023-07-29T23:42:39.631000Z"
    }
   },
   "source": [
    "# Let us select a simple example\n",
    "my_test = \"Where is Monte Porzio Catone ?\"\n",
    "#my_test = \"il governante, ora in esilio, ritornerà nel paese per le elezioni, merda\"\n",
    "label = \"_\"\n",
    "\n",
    "# Let us convert it in a pair that can be used to populate a dataloader...\n",
    "my_list = [(my_test, label)]\n",
    "my_data_loader = generate_data_loader(my_list, label_to_id_map, tokenizer)\n",
    "\n",
    "# ... and reuse the evaluate method\n",
    "_, _ = evaluate(my_data_loader, best_model, print_classification_output=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "labels = dict()\n",
    "short_to_desc = {'ABBR': 'ABBREVIATION', 'ENTY': 'ENTITY', 'DESC': 'DESCRIPTION', 'HUM': 'HUMAN', 'LOC': 'LOCATION',\n",
    "                 'NUM': 'NUMERIC'}\n",
    "desc_to_short = {k2: k1 for k1, k2 in short_to_desc.items()}\n",
    "with open('labels.txt', mode='r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        if line.startswith('\\''):\n",
    "            coarse_lbl, fine_label = line[1:line.rindex('\\'')].split(':')\n",
    "            desc = line[line.rindex(':') + 1: -2].strip()\n",
    "            labels[coarse_lbl][fine_label] = desc\n",
    "        else:\n",
    "            lbl = line[:-2]\n",
    "            labels[desc_to_short[lbl]] = dict()\n",
    "\n",
    "with open('./labels_dict.pickle', mode='wb') as f:\n",
    "    pickle.dump({'short_to_desc': short_to_desc, 'desc_to_short': desc_to_short, 'labels': labels}, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-29T23:42:39.600996Z",
     "end_time": "2023-07-29T23:42:39.640963Z"
    }
   }
  }
 ]
}
